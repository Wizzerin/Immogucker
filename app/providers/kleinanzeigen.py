import asyncio
import logging
import time
from typing import List, Dict, Any
from bs4 import BeautifulSoup
from selenium.common.exceptions import TimeoutException
from app.providers.base import BaseProvider
from app.core.browser import browser_manager

logger = logging.getLogger(__name__)


class KleinanzeigenProvider(BaseProvider):
    async def fetch_listings(self, url: str, driver: Any = None) -> List[Dict]:
        if not driver:
            return []

        logger.info(f"ü§ñ [Kleinanzeigen] –†–∞–±–æ—Ç–∞—é –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –æ–∫–Ω–µ...")
        listings = []

        try:
            loop = asyncio.get_event_loop()

            def interact():
                try:
                    # [FIX] –°–ë–†–û–° –°–û–°–¢–û–Ø–ù–ò–Ø –ë–†–ê–£–ó–ï–†–ê
                    # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —É–±–∏–≤–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç—ã Immowelt, –∫–æ—Ç–æ—Ä—ã–µ –≤–µ—à–∞—é—Ç –±—Ä–∞—É–∑–µ—Ä
                    driver.get("about:blank")
                    time.sleep(1)

                    # –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ Kleinanzeigen —Å —á–∏—Å—Ç–æ–π —Å–æ–≤–µ—Å—Ç—å—é
                    driver.set_page_load_timeout(25)
                    driver.get(url)

                except TimeoutException:
                    logger.warning("‚ö†Ô∏è Kleinanzeigen: Timeout –∑–∞–≥—Ä—É–∑–∫–∏. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –∏ –ø–∞—Ä—à—É —á—Ç–æ –µ—Å—Ç—å.")
                    try:
                        driver.execute_script("window.stop();")
                    except:
                        pass
                except Exception as e:
                    raise e

                # –ó–∞–∫—Ä—ã—Ç–∏–µ –∫—É–∫–∏
                try:
                    driver.execute_script("document.getElementById('gdpr-banner-accept').click();")
                except:
                    pass

                return driver.page_source

            html = await loop.run_in_executor(None, interact)

            try:
                driver.execute_script("window.scrollTo(0, 300);")
                await asyncio.sleep(1)
            except:
                pass

            soup = BeautifulSoup(html, 'lxml')

            # --- –ü–ê–†–°–ò–ù–ì ---
            items = []
            main_list = soup.find("ul", id="srchrslt-adtable")

            if main_list:
                items = main_list.find_all("li", class_="ad-listitem")

            if not items:
                items = soup.find_all("article", class_="aditem")

            logger.info(f"üîé Kleinanzeigen: –ù–∞–π–¥–µ–Ω–æ {len(items)} –±–ª–æ–∫–æ–≤")

            if len(items) == 0:
                # –ï—Å–ª–∏ —Å–Ω–æ–≤–∞ 0 ‚Äî –º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —á—Ç–æ –≤–∏–¥–∏—Ç –±–æ—Ç
                # with open("kleinanzeigen_fail_debug.html", "w", encoding="utf-8") as f: f.write(html)
                pass

            for i, item in enumerate(items):
                try:
                    if item.name == 'li':
                        article = item.find("article")
                    else:
                        article = item

                    if not article: continue

                    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ (–∏—â–µ–º –≤ h2, —á—Ç–æ–±—ã –Ω–µ –±—Ä–∞—Ç—å —Ü–∏—Ñ—Ä—ã —Å –∫–∞—Ä—Ç–∏–Ω–æ–∫)
                    h2 = article.find("h2")
                    if not h2: continue
                    link_tag = h2.find("a", href=True)
                    if not link_tag: continue

                    title = link_tag.text.strip()

                    # –°—Å—ã–ª–∫–∞
                    partial_link = link_tag['href']
                    if "kleinanzeigen.de" not in partial_link:
                        link = f"https://www.kleinanzeigen.de{partial_link}"
                    else:
                        link = partial_link

                    # –¶–µ–Ω–∞ (—Å –æ—á–∏—Å—Ç–∫–æ–π –æ—Ç –∑–Ω–∞—á–∫–∞ –µ–≤—Ä–æ, —á—Ç–æ–±—ã –Ω–µ –¥–≤–æ–∏–ª–æ—Å—å)
                    price = "VB"
                    price_tag = article.find("p", class_=lambda x: x and "price" in x)
                    if price_tag:
                        raw_price = price_tag.text.strip()
                        clean_price = raw_price.replace("‚Ç¨", "").replace("VB", "").strip()
                        if clean_price:
                            price = clean_price
                        else:
                            price = raw_price

                    # –ü–ª–æ—â–∞–¥—å
                    area = "-"
                    details_div = article.find("div", class_=lambda x: x and "simple-attribute" in x)
                    raw_text = article.get_text(" ", strip=True)

                    if "m¬≤" in raw_text:
                        words = raw_text.split()
                        for idx, w in enumerate(words):
                            if "m¬≤" in w or "m2" in w:
                                if idx > 0:
                                    prev_word = words[idx - 1].replace(",", ".")
                                    if prev_word.replace(".", "").isdigit():
                                        area = prev_word
                                break

                    listings.append({
                        'titel': title,
                        'preis': price,
                        'flaeche': area,
                        'link': link,
                        'quelle': 'Kleinanzeigen'
                    })

                except Exception as e:
                    continue

        except Exception as e:
            logger.error(f"‚ùå Kleinanzeigen Error: {e}")
            await browser_manager.force_restart()

        return listings